package TestDataFrame

import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.log4j._
import java.util.ArrayList
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.SparkSession
import spark.implicits._
//import spark.implicits._

object dframe {

  def main(args: Array[String]) {

    
    
    
    val sc = new SparkContext("local[*]", "prueba")
    val sqlContext = new org.apache.spark.sql.SQLContext(sc)
    val dfs = sqlContext.read.json("employee.json")
    
    dfs.show()
    dfs.printSchema()
    
    //Solo mostrar una columna
    dfs.select("name").show()
    //Filtrar el DataFrame
    dfs.filter(dfs("age") > 28).show()
    
    //Agrupados por edad
    //val x = dfs.groupBy("age").count()
    
    //dfs.groupBy("age").sum("age").show()
    
    //x.show()
    
    dfs.select("name", "age" + 1).show()
    
    
    
  }

}