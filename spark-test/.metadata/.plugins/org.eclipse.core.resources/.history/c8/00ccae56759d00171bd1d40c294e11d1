package tablon

import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.log4j._

object clientesRecurrentes {
  
  def kpi_clientes_recurrentes(ruta: String,inicio:String, fin:String,establecimiento:String) = {
      
    val sc = new SparkContext("local[*]", "clientesRecurrentes")
	val rddTablon = sc.textFile(ruta)
	val rddDepurado = rddTablon.map(r => r.split("\t")).map(r => (r(6),r(14),r(25)))
	val rddFiltrado = rddDepurado.filter(x => (x._3 >= inicio && x._3 <= fin) && x._1 == establecimiento)
	val rddXclientes = rddFiltrado.map(x => (x._1+","+x._2,1)).reduceByKey(_+_)
	val rddVisitas = rddXclientes.map(x => (x._1.split(","))).map(x => (x(0),x(2))).filter(x => x._1 == 1)
	
	println("Registros detallados")
	rddFiltrado.foreach(println)
	println("Número de registros")
	println(rddFiltrado.count())
	println("Agrupación por clientes")
	rddXclientes.foreach(println)
	println(rddXclientes.count())

	println("Rango 1")
	 rddVisitas.foreach(println)
	
    }
  
  
  def main(args: Array[String]) {
    
    kpi_clientes_recurrentes("tablon.tsv","201609","201610","100070934")
    
    
    
  }
  
}