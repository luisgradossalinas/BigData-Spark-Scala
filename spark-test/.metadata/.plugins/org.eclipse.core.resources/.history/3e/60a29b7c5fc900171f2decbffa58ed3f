package hiveTest

import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.types._
import org.apache.spark.sql._
import org.apache.spark.sql.functions._

object DosConceptos {

  var sc = new SparkContext("local[*]", "DosConceptos")
  var sqlContext = new org.apache.spark.sql.SQLContext(sc)

  var hiveContext = new org.apache.spark.sql.hive.HiveContext(sc)

  def byClientes2(ruta: String, esta: List[String], inicio: String, fin: String, conceptos: String): DataFrame = {

    val concepto1 = conceptos.split(",")(0)
    val concepto2 = conceptos.split(",")(1)
    val cabeceras = "CODESTABLECIMIENTO,CODMES," + conceptos
    
    var tablonDF = hiveContext.sql("SELECT "+cabeceras+" FROM LONDON_SMART.TABLON limit 100000")

    return tablonDF.filter((tablonDF("CODESTABLECIMIENTO") isin (esta: _*)) && (!tablonDF(concepto1).equalTo("\\N"))
      && (!tablonDF(concepto2).equalTo("\\N")) && (tablonDF("CODMES")
        .between(inicio, fin)))
      .groupBy("CODMES", concepto1, concepto2)
      .agg(count("CODMES").as("TOTAL"))
      .orderBy("CODMES", concepto1, concepto2)

  }

  def main(args: Array[String]) {

    val kpiCalculo2 = byClientes2("tablon.tsv", List("100070934", "100070905"), "201501", "201512", "SEXO_CLIENTE,RANGO_SUELDO")
    kpiCalculo2.show()

  }

}