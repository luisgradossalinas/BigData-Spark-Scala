package TestDataFrame

import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.log4j._
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.types._
import org.apache.spark.sql._
import org.apache.spark.sql.functions._

object NConceptos {

  /*
   * 17 => RUC
   * 6 => CODESTABLECIMIENTO
   * 12 => MTOTRANSACCION
   * 14 => CODCLAVECIC_CLIENTE
   * 25 => CODMES
   * 43 => SEXO_CLIENTE
   * 46 => RANGO_SUELDO
   * 47 => TIPUSODIGITAL
   * 48 => DESTIPUSODIGITAL
   * 57 => RANGO_EDAD
   */

  var spark = SparkSession
    .builder
    .appName("PocDF")
    .master("local[*]")
    .getOrCreate()

  //Esta función recibirá 2 conceptos por ejemplo SEXO y NIVEL_INGRESO
  def byClientes2Conceptos(ruta: String, esta: List[String], inicio: String, fin: String, conceptos: String): DataFrame = {

    val rddTablon = spark.sparkContext.textFile(ruta).map(r => r.split("\t")).map(r => Row(r(6), r(25), r(43), r(46)))
    val cabeceras = "CODESTABLECIMIENTO CODMES "+conceptos
    val encabezado = cabeceras.split(" ")
    val concepto1 = encabezado(2)
    val concepto2 = encabezado(3)
    val camposDF = cabeceras.split(" ").map(fieldName => StructField(fieldName, StringType, nullable = true))
    val schema = StructType(camposDF)

    val tablonDF = spark.createDataFrame(rddTablon, schema)

    return tablonDF.filter((tablonDF("CODESTABLECIMIENTO") isin (esta: _*)) && (!tablonDF(concepto1).equalTo("\\N")) && (!tablonDF(concepto2).equalTo("\\N")) && (tablonDF("CODMES")
      .between(inicio, fin)))
      .groupBy("CODMES", concepto1, concepto2)
      .agg(count("CODMES").as("TOTAL"))
      .orderBy("CODMES", concepto1, concepto2)

  }

  def main(args: Array[String]) {

    val kpiCalculo = byClientes2Conceptos("tablon.tsv", List("100070934", "100070905"), "201501", "201512","SEXO_CLIENTE RANGO_SUELDO")
    kpiCalculo.show()

    val cabeceras = "CODESTABLECIMIENTO CODMES SEXO_CLIENTE RANGO_SUELDO"
    val encabezado = cabeceras.split(" ")
    println(encabezado(2))
    
    println("Probando con Spark")

    var equivalencias = List(("SEXO_CLIENTE", 43), ("RANGO_SUELDO", 46), ("DESTIPUSODIGITAL", 48), ("RANGO_EDAD", 57))
    //println(equivalencias(0)._2)

    //var conceptos = List("SEXO_CLIENTE", "RANGO_SUELDO", "DESTIPUSODIGITAL", "RANGO_EDAD")
    /*
    var conceptos = List("SEXO_CLIENTE", "RANGO_SUELDO")
    var v = new Array[Int](conceptos.length) //Este array guardará los índices de los conceptos

    var contador = 0
    var cont = 0
    for (name <- equivalencias) {
      for (concepto <- conceptos) {
        if (equivalencias(contador)._1 == conceptos(contador)) {
          v(cont) = equivalencias(contador)._2
          cont = cont + 1
        }
      }

      //println(equivalencias(contador)._2)
      contador = contador + 1

    }
    
    println(v(0))
*/
  }

}